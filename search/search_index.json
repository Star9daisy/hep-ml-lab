{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"HEP ML Lab (HML)","text":""},{"location":"#introduction","title":"Introduction","text":"<p>HEP-ML-Lab is an end-to-end framework used for research combining high-energy physics phenomenology with machine learning. It covers three main parts: the generation of simulated data, the conversion of data representation, and the application of analysis approaches.</p> <p>With HML, researchers can easily compare the performance between traditional methods and modern machine learning algorithms, and obtain robust and reproducible results.</p> <p>To get started, please check out the documents.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install hep-ml-lab\n</code></pre> <p>Check out the install via pip for more details of prerequisites and post-installation steps or install via Docker for a hassle-free experience.</p>"},{"location":"#module-overview","title":"Module overview","text":"<ul> <li><code>hml.generators</code>: API of Madgraph5 for simulating colliding events;</li> <li><code>hml.physics_objects</code>: General physics objects;</li> <li><code>hml.observables</code>: General observables in jet physics;</li> <li><code>hml.representations</code>: Different data structure used to represent an event;</li> <li><code>hml.datasets</code>: Existing datasets and helper classes for creating new datasets;</li> <li><code>hml.approaches</code>: Cuts, trees and networks for classification;</li> <li><code>hml.metrics</code>: Metrics used in classical signal vs background analysis;</li> </ul>"},{"location":"history/","title":"History","text":""},{"location":"history/#v041","title":"v0.4.1","text":"<ul> <li>Fix module overview image in README.</li> <li>Fix <code>GradientBoostedDecisionTree</code> to be compatible with different <code>sklearn</code> versions.</li> <li>Fix <code>hml.datasets.SetDataset.show</code> to display the correct rows and columns.</li> <li>Rename the <code>parse</code> and <code>register</code> functions to <code>parse_physics_object</code>, <code>parse_observable</code>, and <code>register_observable</code>.</li> <li>Update the installation document.</li> </ul>"},{"location":"history/#v040","title":"v0.4.0","text":"<p>This version refactors most of the codebase to make it compatible with the array (from <code>awkward</code> and <code>uproot</code>) representation of the data.</p>"},{"location":"history/#v0301","title":"v0.3.0.1","text":"<ul> <li>Fix a bug that Madgraph5 may run into an infinite loop caused by HML keeping   removing py.py file during initialization.</li> <li>Fix nan value not implemented in Fileter.</li> <li>Fix the wrong order of runs when using <code>hml.generators.Madgraph5.runs</code> and   <code>hml.generators.Madgraph5.summary</code>.</li> <li>Fix the typo \"g1\" in quickstart.</li> </ul>"},{"location":"history/#v030","title":"v0.3.0","text":"<ul> <li>New Madgraph5 API now is closer to the original Madgraph5 CLI.</li> <li>New Observable parsing system makes it easier to use and define new observables.</li> <li>New CutAndCout and BoostedDecisionTree in Keras style.</li> </ul>"},{"location":"history/#v022","title":"v0.2.2","text":"<ul> <li>Change output structure of <code>hml.generators.Madgraph5</code> to ensure reproducibility.</li> <li>Refactor <code>hml.generators.Madgraph5</code> and <code>hml.generators.MG5Run</code> to make   them more robust.</li> </ul>"},{"location":"history/#v021","title":"v0.2.1","text":"<ul> <li>Add <code>summary</code> to <code>hml.generators.Madgraph5</code> to print a summary of all run.</li> <li>Add <code>remove</code> to <code>hml.generators.Madgraph5</code> to remove a run.</li> <li>Add <code>clean</code> to <code>hml.generators.Madgraph5</code> to remove the output directory.</li> </ul>"},{"location":"api/hml.datasets/","title":"hml.datasets","text":""},{"location":"api/hml.generators/","title":"hml.generators","text":""},{"location":"api/hml.metrics/","title":"hml.metrics","text":""},{"location":"api/hml.observables/","title":"hml.observables","text":""},{"location":"api/hml.representations/","title":"hml.representations","text":""},{"location":"api/hml.approaches/cuts/","title":"cuts","text":""},{"location":"api/hml.approaches/trees/","title":"trees","text":""},{"location":"api/hml.approaches/networks/mlps/","title":"mlps","text":""},{"location":"api/physics_objects/collective/","title":"collective","text":""},{"location":"api/physics_objects/collective/#hml.physics_objects.collective.Collective","title":"Collective","text":"<p>             Bases: <code>PhysicsObject</code></p> <p>A collective physics object</p> Source code in <code>hml/physics_objects/collective.py</code> <pre><code>class Collective(PhysicsObject):\n\"\"\"A collective physics object\"\"\"\ndef __init__(\nself,\nbranch: str,\nstart: int | None = None,\nstop: int | None = None,\n) -&gt; None:\nself._branch = branch\nself._start = start\nself._stop = stop\n@classmethod\ndef from_name(cls, name: str) -&gt; Collective:\nif re.match(r\"^[a-zA-Z]+$|^[a-zA-Z]+\\d*:\\d*$\", name.strip()):\nmatch_ = re.match(r\"^([a-zA-Z]+)(\\d*):?(\\d*)$\", name)\nbranch, start, stop = match_.groups()\nstart = int(start) if start != \"\" else None\nstop = int(stop) if stop != \"\" else None\nreturn cls(branch, start, stop)\nraise ValueError(f\"Invalid name '{name}' for a collective physics object\")\n@property\ndef start(self) -&gt; int | None:\nreturn self._start\n@property\ndef stop(self) -&gt; int | None:\nreturn self._stop\n@property\ndef branch(self) -&gt; str:\nreturn self._branch\n@property\ndef slices(self) -&gt; list[slice]:\nreturn [slice(self.start, self.stop)]\n@property\ndef name(self) -&gt; str:\nif self.start is None and self.stop is None:\nreturn f\"{self.branch}\"\nelif self.start is None:\nreturn f\"{self.branch}:{self.stop}\"\nelif self.stop is None:\nreturn f\"{self.branch}{self.start}:\"\nelse:\nreturn f\"{self.branch}{self.start}:{self.stop}\"\n@property\ndef config(self) -&gt; dict:\nreturn {\"branch\": self.branch, \"start\": self.start, \"stop\": self.stop}\n</code></pre>"},{"location":"api/physics_objects/collective/#hml.physics_objects.collective.is_collective","title":"is_collective","text":"<pre><code>is_collective(object_)\n</code></pre> <p>Check if an object is a collective physics object</p> Source code in <code>hml/physics_objects/collective.py</code> <pre><code>def is_collective(object_: PhysicsObject | str) -&gt; bool:\n\"\"\"Check if an object is a collective physics object\"\"\"\nif isinstance(object_, PhysicsObject):\nreturn isinstance(object_, Collective)\nreturn bool(re.match(r\"^[a-zA-Z]+$|^[a-zA-Z]+\\d*:\\d*$\", object_))\n</code></pre>"},{"location":"api/physics_objects/multiple/","title":"multiple","text":""},{"location":"api/physics_objects/multiple/#hml.physics_objects.multiple.Multiple","title":"Multiple","text":"<p>             Bases: <code>PhysicsObject</code></p> <p>A multiple physics object</p> Source code in <code>hml/physics_objects/multiple.py</code> <pre><code>class Multiple(PhysicsObject):\n\"\"\"A multiple physics object\"\"\"\ndef __init__(self, all: list[PhysicsObject | str]) -&gt; None:\nself._all = self._init_all(all)\ndef _init_all(self, objects: list[PhysicsObject | str]) -&gt; list[PhysicsObject]:\noutput = []\nfor obj in objects:\nif isinstance(obj, PhysicsObject):\noutput.append(obj)\nelif is_single(obj):\noutput.append(Single.from_name(obj))\nelif is_collective(obj):\noutput.append(Collective.from_name(obj))\nelse:\noutput.append(Nested.from_name(obj))\nreturn output\n@classmethod\ndef from_name(cls, name: str) -&gt; Multiple:\nif \",\" in name:\nall_ = name.split(\",\")\nreturn cls(all_)\nraise ValueError(f\"Invalid name '{name}' for a multiple physics object\")\n@property\ndef all(self) -&gt; list[PhysicsObject]:\nreturn self._all\n@property\ndef branch(self) -&gt; list[str]:\nreturn [obj.branch for obj in self.all]\n@property\ndef slices(self) -&gt; list[list[slice]]:\nreturn [i.slices for i in self.all]\n@property\ndef name(self) -&gt; str:\nreturn \",\".join(obj.name for obj in self.all)\n@property\ndef config(self) -&gt; dict:\nreturn {\"all\": [i.name for i in self.all]}\n</code></pre>"},{"location":"api/physics_objects/multiple/#hml.physics_objects.multiple.is_multiple","title":"is_multiple","text":"<pre><code>is_multiple(object_, supported_types=None)\n</code></pre> <p>Check if an object is a multiple physics object</p> Source code in <code>hml/physics_objects/multiple.py</code> <pre><code>def is_multiple(\nobject_: PhysicsObject | str,\nsupported_types: list[PhysicsObject | str] | None = None,\n) -&gt; bool:\n\"\"\"Check if an object is a multiple physics object\"\"\"\nif isinstance(object_, str):\ntry:\nobject_ = Multiple.from_name(object_)\nexcept Exception:\nreturn False\nif supported_types is None:\nreturn True\nsupported_types = [\ni.lower() if isinstance(i, str) else i.__class__.__name__.lower()\nfor i in supported_types\n]\nfor obj in object_.all:\nif obj.__class__.__name__.lower() not in supported_types:\nreturn False\nreturn True\n</code></pre>"},{"location":"api/physics_objects/nested/","title":"nested","text":""},{"location":"api/physics_objects/nested/#hml.physics_objects.nested.Nested","title":"Nested","text":"<p>             Bases: <code>PhysicsObject</code></p> <p>A nested physics object</p> Source code in <code>hml/physics_objects/nested.py</code> <pre><code>class Nested(PhysicsObject):\n\"\"\"A nested physics object\"\"\"\ndef __init__(\nself,\nmain: PhysicsObject | str,\nsub: PhysicsObject | str,\n) -&gt; None:\nself._main = self._init_object(main)\nself._sub = self._init_object(sub)\ndef _init_object(self, object_: PhysicsObject | str) -&gt; PhysicsObject:\nif isinstance(object_, PhysicsObject):\nreturn object_\nelif is_single(object_):\nreturn Single.from_name(object_)\nelse:\nreturn Collective.from_name(object_)\n@classmethod\ndef from_name(cls, name: str) -&gt; Nested:\nif \".\" in name:\nmain, sub = name.split(\".\")\nreturn cls(main, sub)\nraise ValueError(f\"Invalid name '{name}' for a nested physics object\")\n@property\ndef main(self) -&gt; PhysicsObject:\nreturn self._main\n@property\ndef sub(self) -&gt; PhysicsObject:\nreturn self._sub\n@property\ndef branch(self) -&gt; str:\nreturn f\"{self.main.branch}.{self.sub.branch}\"\n@property\ndef slices(self) -&gt; list[slice]:\nreturn [*self.main.slices, *self.sub.slices]\n@property\ndef name(self) -&gt; str:\nreturn f\"{self.main.name}.{self.sub.name}\"\n@property\ndef config(self) -&gt; dict:\nreturn {\"main\": self.main.name, \"sub\": self.sub.name}\n</code></pre>"},{"location":"api/physics_objects/nested/#hml.physics_objects.nested.is_nested","title":"is_nested","text":"<pre><code>is_nested(object_)\n</code></pre> <p>Check if an object is a nested physics object</p> Source code in <code>hml/physics_objects/nested.py</code> <pre><code>def is_nested(object_: PhysicsObject | str) -&gt; bool:\n\"\"\"Check if an object is a nested physics object\"\"\"\nif isinstance(object_, PhysicsObject):\nreturn isinstance(object_, Nested)\nreturn bool(re.match(r\"^[a-zA-Z]+\\d*:?\\d*\\.[a-zA-Z]+\\d*:?\\d*$\", object_))\n</code></pre>"},{"location":"api/physics_objects/single/","title":"single","text":""},{"location":"api/physics_objects/single/#hml.physics_objects.single.Single","title":"Single","text":"<p>             Bases: <code>PhysicsObject</code></p> <p>A single physics object</p> Source code in <code>hml/physics_objects/single.py</code> <pre><code>class Single(PhysicsObject):\n\"\"\"A single physics object\"\"\"\ndef __init__(self, branch: str, index: int) -&gt; None:\nself._branch = branch\nself._index = index\n@classmethod\ndef from_name(cls, name: str) -&gt; Single:\nif match_ := re.match(r\"^([a-zA-Z]+)(\\d+)$\", name.strip()):\nbranch, index = match_.groups()\nreturn cls(branch, int(index))\nraise ValueError(f\"Invalid name '{name}' for a single physics object\")\n@property\ndef index(self) -&gt; int:\nreturn self._index\n@property\ndef branch(self) -&gt; str:\nreturn self._branch\n@property\ndef slices(self) -&gt; list[slice]:\nreturn [slice(self.index, self.index + 1)]\n@property\ndef name(self) -&gt; str:\nreturn f\"{self.branch}{self.index}\"\n@property\ndef config(self) -&gt; dict:\nreturn {\"branch\": self.branch, \"index\": self.index}\n</code></pre>"},{"location":"api/physics_objects/single/#hml.physics_objects.single.is_single","title":"is_single","text":"<pre><code>is_single(object_)\n</code></pre> <p>Check if an object is a single physics object</p> Source code in <code>hml/physics_objects/single.py</code> <pre><code>def is_single(object_: PhysicsObject | str) -&gt; bool:\n\"\"\"Check if an object is a single physics object\"\"\"\nif isinstance(object_, PhysicsObject):\nreturn isinstance(object_, Single)\nreturn bool(re.match(r\"^[a-zA-Z]+\\d+$\", object_))\n</code></pre>"},{"location":"guides/","title":"Guides","text":"<p>To help you get started with <code>hml</code>, we provide a series of guides.</p> <p>This series shows how to use the <code>hml</code> package to do a simple jet tagging task of the Z boson and QCD to dijets processes.</p> <p>These guides together form a complete workflow of <code>hml</code>: generate events, create datasets, apply different approaches and evaluate the performance of them. It's recommended to read them in order.</p>"},{"location":"guides/01_generate_events/","title":"Generate events","text":"<p>This guide shows how to use the <code>Madgraph5</code> class to generate events WW and QCD to dijet processes. To get started, let\u2019s import some necessary classes from <code>generators</code> module:</p> <pre><code>from hml.generators import Madgraph5, Madgraph5Run\n</code></pre> <p>API is designed to be as much similar as the CLI. The following table shows the correspondence between the CLI commands and the API methods:</p> CLI command API method <code>import model sm</code> <code>g.import_model(\"sm\")</code> <code>define l = e+ e-</code> <code>g.define(\"l = e+ e-\")</code> <code>generate p p &gt; j j</code> <code>add process p p &gt; j j j</code> <code>g.generate(\"p p &gt; j j\", \"p p &gt; j j j\")</code> <code>display diagrams Diagrams</code> <code>g.display_diagrams(\"Diagrams\")</code> <code>output ./test</code> <code>g.output(\"./test\")</code> <code>launch</code> <code>g.launch(...)</code>"},{"location":"guides/01_generate_events/#initialization","title":"Initialization","text":"<p>The Madgraph5 API (application programming interface) works similarly to the Madgraph5 CLI (command line interface). It uses CLI commands to generate events, so the very first step is to connect to the Madgraph5 executable file:</p> <pre><code>g = Madgraph5(executable=\"mg5_aMC\", verbose=1)\n</code></pre> <pre><code>************************************************************\n*                                                          *\n*                     W E L C O M E to                     *\n*              M A D G R A P H 5 _ a M C @ N L O           *\n*                                                          *\n*                                                          *\n*                 *                       *                *\n*                   *        * *        *                  *\n*                     * * * * 5 * * * *                    *\n*                   *        * *        *                  *\n*                 *                       *                *\n*                                                          *\n*         VERSION 3.5.3                 2023-12-23         *\n*                                                          *\n*    The MadGraph5_aMC@NLO Development Team - Find us at   *\n*              http://madgraph.phys.ucl.ac.be/             *\n*                            and                           *\n*            http://amcatnlo.web.cern.ch/amcatnlo/         *\n*                                                          *\n*               Type 'help' for in-line help.              *\n*           Type 'tutorial' to learn how MG5 works         *\n*    Type 'tutorial aMCatNLO' to learn how aMC@NLO works   *\n*    Type 'tutorial MadLoop' to learn how MadLoop works    *\n*                                                          *\n************************************************************\nload MG5 configuration from ../../../../softwares/madgraph5/input/mg5_configuration.txt \nfastjet-config does not seem to correspond to a valid fastjet-config executable (v3+). We will use fjcore instead.\n Please set the 'fastjet'variable to the full (absolute) /PATH/TO/fastjet-config (including fastjet-config).\n MG5_aMC&gt; set fastjet /PATH/TO/fastjet-config\n\neMELA-config does not seem to correspond to a valid eMELA-config executable.\n Please set the 'fastjet'variable to the full (absolute) /PATH/TO/eMELA-config (including eMELA-config).\n MG5_aMC&gt; set eMELA /PATH/TO/eMELA-config\n\nset lhapdf to lhapdf-config\nset lhapdf to lhapdf-config\nUsing default text editor \"vi\". Set another one in ./input/mg5_configuration.txt\nNo valid eps viewer found. Please set in ./input/mg5_configuration.txt\nNo valid web browser found. Please set in ./input/mg5_configuration.txt\nLoading default model: sm\nINFO: Restrict model sm with file ../../../../softwares/madgraph5/models/sm/restrict_default.dat . \nINFO: Run \"set stdout_level DEBUG\" before import for more information. \nINFO: Change particles name to pass to MG5 convention \nDefined multiparticle p = g u c d s u~ c~ d~ s~\nDefined multiparticle j = g u c d s u~ c~ d~ s~\nDefined multiparticle l+ = e+ mu+\nDefined multiparticle l- = e- mu-\nDefined multiparticle vl = ve vm vt\nDefined multiparticle vl~ = ve~ vm~ vt~\nDefined multiparticle all = g u c d s u~ c~ d~ s~ a ve vm vt e- mu- ve~ vm~ vt~ e+ mu+ t b t~ b~ z w+ h w- ta- ta+\nMG5_aMC&gt;\n</code></pre> <ul> <li><code>executable</code> refers to the path of the <code>mg5_aMC</code> executable file.</li> <li><code>verbose</code> is used to control the output level. The default value is 1 showing all the information as the CLI does. If it is set to 0, no information will be displayed.</li> </ul>"},{"location":"guides/01_generate_events/#generate-the-process","title":"Generate the process","text":"<p>We take \"p p &gt; w+ z\" as the first example. We want to give the W boson a boost to simulate there is a heavy intermediate particles from new physics. So no decay chain is specified here. In the launch part, W boson decays to two jets and Z boson decays invisibly to ensure the fatjet is consistent with the W boson.</p> <pre><code>g.generate(\"p p &gt; w+ z\")\n</code></pre> <pre><code>generate p p &gt; w+ z\nINFO: Checking for minimal orders which gives processes. \nINFO: Please specify coupling orders to bypass this step. \nINFO: Trying process: u d~ &gt; w+ z WEIGHTED&lt;=4 @1  \nINFO: Process has 3 diagrams \nINFO: Trying process: u s~ &gt; w+ z WEIGHTED&lt;=4 @1  \nINFO: Trying process: c d~ &gt; w+ z WEIGHTED&lt;=4 @1  \nINFO: Trying process: c s~ &gt; w+ z WEIGHTED&lt;=4 @1  \nINFO: Process has 3 diagrams \nINFO: Process d~ u &gt; w+ z added to mirror process u d~ &gt; w+ z \nINFO: Process s~ c &gt; w+ z added to mirror process c s~ &gt; w+ z \n2 processes with 6 diagrams generated in 0.025 s\nTotal: 2 processes with 6 diagrams\n</code></pre> <p>Note</p> <p>The <code>add process</code> and <code>generate</code> commands from CLI are combined into <code>generate</code> in the API. So you can directly add processes one by one. For example: <code>g.generate(\"p p &gt; w+ j\", \"p p &gt; w- j\")</code></p> <p>After generating the process, it is crutial to check the feynman diagram before moving on:</p> <pre><code>g.display_diagrams()\n</code></pre> <pre><code>display diagrams Diagrams\nDrawing Process: u d~ &gt; w+ z WEIGHTED&lt;=4 @1\nWrote file Diagrams/diagrams_1_udx_wpz.eps\nopen Diagrams/diagrams_1_udx_wpz.eps\nNot able to open file Diagrams/diagrams_1_udx_wpz.eps since no program configured.Please set one in ./input/mg5_configuration.txt\nDrawing Process: c s~ &gt; w+ z WEIGHTED&lt;=4 @1\nWrote file Diagrams/diagrams_1_csx_wpz.eps\nopen Diagrams/diagrams_1_csx_wpz.eps\nNot able to open file Diagrams/diagrams_1_csx_wpz.eps since no program configured.Please set one in ./input/mg5_configuration.txt\ntime to draw 0.012159109115600586\n</code></pre> <pre><code>!tree Diagrams\n</code></pre> <pre><code>Diagrams/\n\u251c\u2500\u2500 diagrams_1_csx_wpz.eps\n\u251c\u2500\u2500 diagrams_1_csx_wpz.pdf\n\u251c\u2500\u2500 diagrams_1_udx_wpz.eps\n\u2514\u2500\u2500 diagrams_1_udx_wpz.pdf\n\n0 directories, 4 files\n</code></pre> <ul> <li>By default, the diagram is stored in the <code>Diagrams</code> folder in the current directory. You can change the path by setting the parameter <code>diagram_dir</code>.</li> <li>The <code>.eps</code> file is converted in <code>.pdf</code> format for convenience.</li> </ul> <p>Finally, we can save the process to a directory:</p> <pre><code>g.output(\"data/pp2wz\")\n</code></pre> <pre><code>output /root/workspace_ssd/projects/hep-ml-lab/examples/data/pp2wz\nINFO: initialize a new directory: pp2wz \nINFO: remove old information in pp2wz \nINFO: Organizing processes into subprocess groups \nINFO: Generating Helas calls for process: u d~ &gt; w+ z WEIGHTED&lt;=4 @1 \nINFO: Processing color information for process: u d~ &gt; w+ z @1 \nINFO: Combined process c s~ &gt; w+ z WEIGHTED&lt;=4 @1 with process u d~ &gt; w+ z WEIGHTED&lt;=4 @1 \nINFO: Creating files in directory P1_qq_wpz \nINFO: Generating Feynman diagrams for Process: u d~ &gt; w+ z WEIGHTED&lt;=4 @1 \nINFO: Finding symmetric diagrams for subprocess group qq_wpz \nGenerated helas calls for 1 subprocesses (3 diagrams) in 0.007 s\nWrote files for 10 helas calls in 0.033 s\nALOHA: aloha starts to compute helicity amplitudes\nALOHA: aloha creates 4 routines in  1.021 s\nThe option auto_update is modified [7] but will not be written in the configuration files.\nIf you want to make this value the default for future session, you can run 'save options --all'\nsave configuration file to /root/workspace_ssd/projects/hep-ml-lab/examples/data/pp2wz/Cards/me5_configuration.txt\nINFO: Use Fortran compiler gfortran \nINFO: Use c++ compiler g++ \nINFO: Generate jpeg diagrams \nINFO: Generate web pages \nOutput to directory /root/workspace_ssd/projects/hep-ml-lab/examples/data/pp2wz done.\nType \"launch\" to generate events from this process, or see\n/root/workspace_ssd/projects/hep-ml-lab/examples/data/pp2wz/README\nRun \"open index.html\" to see more information about this process.\ndisplay diagrams /root/workspace_ssd/projects/hep-ml-lab/examples/data/pp2wz/Diagrams\nDrawing Process: u d~ &gt; w+ z WEIGHTED&lt;=4 @1\nWrote file /root/workspace_ssd/projects/hep-ml-lab/examples/data/pp2wz/Diagrams/diagrams_1_udx_wpz.eps\nopen /root/workspace_ssd/projects/hep-ml-lab/examples/data/pp2wz/Diagrams/diagrams_1_udx_wpz.eps\nNot able to open file /root/workspace_ssd/projects/hep-ml-lab/examples/data/pp2wz/Diagrams/diagrams_1_udx_wpz.eps since no program configured.Please set one in ./input/mg5_configuration.txt\ntime to draw 0.007663726806640625\nProcess log saved to data/pp2wz/Logs/process.log\n</code></pre> <p>Note</p> <p>Even if you don't <code>display_diagram</code> before, the diagram will be saved in the <code>Diagrams</code> folder of the output directory.</p>"},{"location":"guides/01_generate_events/#launch-the-first-run","title":"Launch the first run","text":"<p>It's time to launch the first run. In the CLI, two prompts will show up: one for the tools and the other for the configurations. In the API, they are combined into one method:</p> <pre><code>g.launch(\nshower=\"pythia8\",\ndetector=\"delphes\",\nmadspin=\"none\",\nsettings={\n\"nevents\": 1000,\n\"run_tag\": \"250-300\",\n\"pt_min_pdg\": {24: 250},\n\"pt_max_pdg\": {24: 300},\n},\ndecays=[\n\"w+ &gt; j j\",\n\"z &gt; vl vl~\",\n],\nseed=42,\n)\n</code></pre> <ul> <li><code>shower</code> and <code>detector</code> are options for parton shower and detector simulation tools. Currently, <code>pythia8</code> and <code>delphes</code> are available.</li> <li>In Madgraph5, you can use the <code>set</code> command to change configurations in different cards without opening them. The <code>settings</code> attribute contains these configurations as a Python dictionary.</li> <li>To generate a large number of events, set the <code>multi_run</code> parameter.</li> </ul>"},{"location":"guides/01_generate_events/#check-the-information","title":"Check the information","text":"<p>After the generation is finished, you can use <code>.summary()</code> to check all the information of runs:</p> <pre><code>g.summary()\n</code></pre> <pre>\n                                       p p &gt; w+ z                                        \n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Name      \u2503 Collider         \u2503 Tag     \u2503   Cross section (pb)   \u2503 N events \u2503 Seed \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 run_01[1] \u2502 pp:6500.0x6500.0 \u2502 250-300 \u2502 4.371e-02 +- 4.200e-04 \u2502    1,000 \u2502   42 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   Output: data/pp2wz                                    \n</pre> <ul> <li>The number in the square bracket after \u201crun_01\u201d represents the value of <code>multi_run</code>.</li> <li>A random seed is crucial to reproduce the results, which is why <code>Seed</code> is also displayed.</li> </ul> <p>The data in the summary table are properties of a run:</p> <pre><code>run_01 = g.runs[0]\nprint(f\"Processes: {g.processes}\")\nprint(f\"Name: {run_01.name}\")\nprint(f\"N subruns: {len(run_01.sub_runs)}\")\nprint(f\"Collider: {run_01.collider}\")\nprint(f\"Tag: {run_01.tag}\")\nprint(f\"Cross section: {run_01.cross}\")\nprint(f\"Error: {run_01.error}\")\nprint(f\"N events: {run_01.n_events}\")\nprint(f\"Seed: {run_01.seed}\")\n</code></pre> <pre><code>Processes: ['p p &gt; w+ z']\nName: run_01\nN subruns: 1\nCollider: pp:6500.0x6500.0\nTag: 250-300\nCross section: 0.04371\nError: 0.00042\nN events: 1000\nSeed: 42\n</code></pre> <p>Use <code>events()</code> to retrieve the event files:</p> <pre><code>run_01.events()\n</code></pre> <pre><code>['data/pp2wz/Events/run_01_decayed_1/250-300_delphes_events.root:Delphes']\n</code></pre> <p>This string could be used directly in the <code>uproot</code>:</p> <pre><code>import uproot\nevents = uproot.open(run_01.events()[0])\nevents\n</code></pre> <pre><code>&lt;TTree 'Delphes' (34 branches) at 0x7fc181a77310&gt;\n</code></pre>"},{"location":"guides/01_generate_events/#launch-more-runs","title":"Launch more runs","text":"<p>Under the same process, we can adjust the configurations and launch multiple runs to \"scan\":</p> <pre><code>low_limits = [300, 350, 400, 450]\nhigh_limits = [350, 400, 450, 500]\ng.verbose = 0\nfor low, high in zip(low_limits, high_limits):\nprint(f\"Generating events between {low} and {high} GeV\")\ng.launch(\nshower=\"pythia8\",\ndetector=\"delphes\",\nmadspin=\"none\",\nsettings={\n\"nevents\": 1000,\n\"run_tag\": f\"{low}-{high}\",\n\"pt_min_pdg\": {24: low},\n\"pt_max_pdg\": {24: high},\n},\ndecays=[\n\"w+ &gt; j j\",\n\"z &gt; vl vl~\",\n],\nseed=42,\n)\ng.summary()\n</code></pre> <pre><code>Generating events between 300 and 350 GeV\nGenerating events between 350 and 400 GeV\nGenerating events between 400 and 450 GeV\nGenerating events between 450 and 500 GeV\n</code></pre> <pre>\n                                       p p &gt; w+ z                                        \n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Name      \u2503 Collider         \u2503 Tag     \u2503   Cross section (pb)   \u2503 N events \u2503 Seed \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 run_01[1] \u2502 pp:6500.0x6500.0 \u2502 250-300 \u2502 4.371e-02 +- 4.200e-04 \u2502    1,000 \u2502   42 \u2502\n\u2502 1 \u2502 run_02[1] \u2502 pp:6500.0x6500.0 \u2502 300-350 \u2502 2.021e-02 +- 1.900e-04 \u2502    1,000 \u2502   42 \u2502\n\u2502 2 \u2502 run_03[1] \u2502 pp:6500.0x6500.0 \u2502 350-400 \u2502 9.985e-03 +- 9.400e-05 \u2502    1,000 \u2502   42 \u2502\n\u2502 3 \u2502 run_04[1] \u2502 pp:6500.0x6500.0 \u2502 400-450 \u2502 5.322e-03 +- 8.100e-05 \u2502    1,000 \u2502   42 \u2502\n\u2502 4 \u2502 run_05[1] \u2502 pp:6500.0x6500.0 \u2502 450-500 \u2502 2.972e-03 +- 3.500e-05 \u2502    1,000 \u2502   42 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   Output: data/pp2wz                                    \n</pre>"},{"location":"guides/01_generate_events/#build-a-binary-classification-task","title":"Build a binary classification task","text":"<p>We take QCD to dijet as the background and WZ to dijet as the signal. Both have 10,000 events.</p> <pre><code>wz = Madgraph5(executable=\"mg5_aMC\", verbose=0)\nwz.generate(\"p p &gt; w+ z\")\nwz.output(\"data/pp2wz@10k\")\nwz.launch(\nshower=\"pythia8\",\ndetector=\"delphes\",\nmadspin=\"none\",\nsettings={\n\"nevents\": 10000,\n\"pt_min_pdg\": {24: 250},\n\"pt_max_pdg\": {24: 300},\n},\ndecays=[\n\"w+ &gt; j j\",\n\"z &gt; vl vl~\",\n],\nseed=42,\n)\nwz.summary()\n</code></pre> <pre>\n                                      p p &gt; w+ z                                       \n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Name      \u2503 Collider         \u2503 Tag   \u2503   Cross section (pb)   \u2503 N events \u2503 Seed \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 run_01[1] \u2502 pp:6500.0x6500.0 \u2502 tag_1 \u2502 4.375e-02 +- 1.400e-04 \u2502   10,000 \u2502   42 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                Output: data/pp2wz@10k                                 \n</pre> <pre><code>qcd = Madgraph5(executable=\"mg5_aMC\", verbose=0)\nqcd.generate(\"p p &gt; j j\")\nqcd.output(\"data/pp2jj@10k\")\nqcd.launch(\nshower=\"pythia8\",\ndetector=\"delphes\",\nsettings={\n\"nevents\": 10000,\n\"ptj\": 250,\n\"ptjmax\": 300,\n},\nseed=42,\n)\nqcd.summary()\n</code></pre> <pre>\n                                       p p &gt; j j                                       \n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Name      \u2503 Collider         \u2503 Tag   \u2503   Cross section (pb)   \u2503 N events \u2503 Seed \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 run_01[0] \u2502 pp:6500.0x6500.0 \u2502 tag_1 \u2502 1.161e+04 +- 4.000e+01 \u2502   10,000 \u2502   42 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                Output: data/pp2jj@10k                                 \n\n</pre>"},{"location":"guides/01_generate_events/#read-the-existing-output","title":"Read the existing output","text":"<p>Here we take the \"pp2wz\" as the exising output directory:</p> <ul> <li>If you want to check all information of runs inside this output, use <code>Madgraph5.from_output</code>:</li> </ul> <pre><code>g = Madgraph5.from_output(\"data/pp2wz\", executable=\"mg5_aMC\")\ng.summary()\n</code></pre> <pre>\n                                       p p &gt; w+ z                                        \n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Name      \u2503 Collider         \u2503 Tag     \u2503   Cross section (pb)   \u2503 N events \u2503 Seed \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 0 \u2502 run_01[1] \u2502 pp:6500.0x6500.0 \u2502 250-300 \u2502 4.371e-02 +- 4.200e-04 \u2502    1,000 \u2502   42 \u2502\n\u2502 1 \u2502 run_02[1] \u2502 pp:6500.0x6500.0 \u2502 300-350 \u2502 2.021e-02 +- 1.900e-04 \u2502    1,000 \u2502   42 \u2502\n\u2502 2 \u2502 run_03[1] \u2502 pp:6500.0x6500.0 \u2502 350-400 \u2502 9.985e-03 +- 9.400e-05 \u2502    1,000 \u2502   42 \u2502\n\u2502 3 \u2502 run_04[1] \u2502 pp:6500.0x6500.0 \u2502 400-450 \u2502 5.322e-03 +- 8.100e-05 \u2502    1,000 \u2502   42 \u2502\n\u2502 4 \u2502 run_05[1] \u2502 pp:6500.0x6500.0 \u2502 450-500 \u2502 2.972e-03 +- 3.500e-05 \u2502    1,000 \u2502   42 \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   Output: data/pp2wz                            \n</pre> <ul> <li>Or you only want to retrieve a single run:</li> </ul> <pre><code>run = Madgraph5Run(\"data/pp2wz\", name=\"run_02\")\nrun\n</code></pre> <pre><code>Madgraph5Run run_02 (1 sub runs):\n- collider: pp:6500.0x6500.0\n- tag: 300-350\n- seed: 42\n- cross: 0.02021\n- error: 0.00019\n- n_events: 1000\n</code></pre> <p>Check the doc to learn more about <code>Madgraph5</code>, <code>Madgraph5Run</code>.</p>"},{"location":"guides/02_create_datasets/","title":"Create datasets","text":"<p>This guide demonstrates how to use observable parsing system to create a dataset for future use. With this system, you can create and use observables not only with specific classes but also with simple strings.</p> <p>Start by importing the necessary modules:</p> <pre><code>import uproot\nfrom hml.generators import Madgraph5\nfrom hml.representations import Image\nfrom hml.datasets import SetDataset, ImageDataset\nfrom hml.approaches import Cut\n</code></pre>"},{"location":"guides/02_create_datasets/#load-generated-events","title":"Load generated events","text":"<p>As the previous guide showed, HML can handle two cases. Here, we use the <code>Madgraph5</code> class to fetch runs from the output directory:</p> <pre><code>sig = Madgraph5.from_output(\"data/pp2wz@10k\", \"mg5_aMC\")\nbkg = Madgraph5.from_output(\"data/pp2jj@10k\", \"mg5_aMC\")\nsig_events = uproot.open(sig.runs[0].events()[0])\nbkg_events = uproot.open(bkg.runs[0].events()[0])\n</code></pre>"},{"location":"guides/02_create_datasets/#preselection","title":"Preselection","text":"<p>For the processes, we choose three observables: mass and n-subjettiness ratio of the leading fat jet, and the angular distance between the leading and subleading jets. To ensure we can obtain the observables without missing value, it\u2019s necessary to preselect or filter events based on the number of fat jets and jets:</p> <pre><code>preselection = Cut(\"fatjet.size &gt; 0 and jet.size &gt; 1\")\npreselection.read(sig_events)\npreselection.value\n</code></pre> <pre><code>[True,\n True,\n True,\n True,\n True,\n False,\n True,\n True,\n False,\n True,\n ...,\n False,\n True,\n True,\n True,\n False,\n True,\n True,\n False,\n False]\n------------------\ntype: 10000 * bool\n</code></pre> <ul> <li><code>fatjet.size</code> is the observable <code>Size</code> associated with the physics object <code>fatjet</code>. This observable refers to the number of the objects. In a root file, it applies to an entire branch. The physics object corresponds to the branch name (case-insensitive).</li> <li>An observable is always linked to one or more physics objects. This concept inspires HML to create its own observable parsing system: <code>&lt;physics_object&gt;,&lt;another&gt;.&lt;observable&gt;</code>. The <code>physics_object</code> is any branch defined in your root file. Multiple objects are separated by <code>,</code>. For a single object, specify the index directly after the object name, e.g., \"jet0\", \"muon1\".</li> </ul> <p>To extract the observable values, use the <code>read</code> method, which returns a boolean list. The <code>value</code> attribute stores the result.</p>"},{"location":"guides/02_create_datasets/#create-a-set-dataset","title":"Create a set dataset","text":"<p>Now, we use the 1D data container <code>SetDataset</code> to hold these three observables for all events:</p> <pre><code>cut = \"fatjet.size &gt; 0 and jet.size &gt; 1\"\nset_ds = SetDataset([\"fatjet0.mass\", \"fatjet0.tau21\", \"jet0,jet1.delta_r\"])\nset_ds.read(sig_events, 1, [cut])\nset_ds.read(bkg_events, 0, [cut])\n</code></pre> <p>To confirm our choice of observables is powerful enough to differentiate the signal and background, we use <code>show</code> to plot three distributions:</p> <pre><code>set_ds.show()\n</code></pre> <p></p> <p>Right before saving the dataset to the disk, we use the <code>split</code> method to divide the dataset into training and testing sets:</p> <pre><code>set_ds.split(0.7, 0.3, seed=42)\nprint(set_ds.train.samples.shape)\nprint(set_ds.train.targets.shape)\nset_ds.save(\"data/wjj_vs_qcd_set.ds\")\n</code></pre> <pre><code>(12644, 3)\n(12644,)\n</code></pre> <p>The <code>split</code> method also supports the validation set: <code>set_ds.split(0.7, 0.2, 0.1)</code>.</p>"},{"location":"guides/02_create_datasets/#create-an-image-dataset","title":"Create an image dataset","text":"<p>Besides a set dataset, we can also represent each event as an image and then create a dataset of these images.</p> <pre><code>image_ds = ImageDataset(\nImage(\nheight=\"fatjet0.constituents.phi\",\nwidth=\"fatjet0.constituents.eta\",\nchannel=\"fatjet0.constituents.pt\",\n)\n.with_subjets(\"fatjet0.constituents\", \"kt\", 0.3, 0)\n.translate(origin=\"SubJet0\")\n.rotate(axis=\"SubJet1\", orientation=-90)\n.pixelate(size=(33, 33), range=[(-1.6, 1.6), (-1.6, 1.6)])\n)\n</code></pre> <ul> <li>The <code>Image</code> class is a representation of the image. It takes three arguments: <code>height</code>, <code>width</code>, and <code>channel</code>. The <code>height</code> and <code>width</code> are the observables for the y-axis and x-axis, respectively. The <code>channel</code> is the observable for the pixel intensity.</li> <li>The <code>with_subjets</code> method adds subjets to the image.</li> <li>The <code>translate</code> method moves the origin of the image to the subjet.</li> <li>The <code>rotate</code> method rotates the image.</li> <li>The <code>pixelate</code> method pixelates the image. This step makes the points discrete and produce the real image.</li> </ul> <p>To create the image dataset, we still use the <code>read</code> method:</p> <pre><code>image_ds.read(sig_events, 1, [cut])\nimage_ds.read(bkg_events, 0, [cut])\n</code></pre> <pre><code>#--------------------------------------------------------------------------\n#                         FastJet release 3.4.1\n#                 M. Cacciari, G.P. Salam and G. Soyez                  \n#     A software package for jet finding and analysis at colliders      \n#                           http://fastjet.fr                           \n#                                                                         \n# Please cite EPJC72(2012)1896 [arXiv:1111.6097] if you use this package\n# for scientific work and optionally PLB641(2006)57 [hep-ph/0512210].   \n#                                                                       \n# FastJet is provided without warranty under the GNU GPL v2 or higher.  \n# It uses T. Chan's closest pair algorithm, S. Fortune's Voronoi code,\n# CGAL and 3rd party plugin jet algorithms. See COPYING file for details.\n#--------------------------------------------------------------------------\n</code></pre> <p>To visualize the images, there is also a <code>show</code> method:</p> <pre><code>image_ds.show(norm=\"log\", target=0, show_pixels=True)\nimage_ds.show(norm=\"log\", target=1, show_pixels=True)\n</code></pre> <p> </p> <p>Finally, we split and save the dataset:</p> <pre><code>image_ds.split(0.7, 0.3, seed=42)\nimage_ds.save(\"data/wjj_vs_qcd_image.ds\")\n</code></pre> <p>Check the doc to learn more about observables, representations and datasets.</p>"},{"location":"guides/03_apply_approaches/","title":"Applying Approaches","text":"<p>This guide shows how to use the three built-in approaches to differentiate signal and background. HML streamlines the application of different approaches by adapting them in Keras-style (compile, fit, predict), which is simple to use.</p> <p>Let's get started by importing the necessary modules:</p> <pre><code># General\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras import ops\nfrom rich.table import Table\n# Dataset\nfrom sklearn.preprocessing import MinMaxScaler\nfrom hml.datasets import load_dataset\n# Approaches\nfrom hml.approaches import CutAndCount as CNC\nfrom hml.approaches import GradientBoostedDecisionTree as BDT\nfrom hml.approaches import SimpleCNN as CNN\nfrom hml.approaches import SimpleMLP as MLP\n# Evaluation\nfrom keras.metrics import Accuracy, AUC\nfrom sklearn.metrics import roc_curve\nfrom hml.metrics import MaxSignificance, RejectionAtEfficiency\n# Save and load\nfrom hml.approaches import load_approach\n</code></pre> <p>Then we use a dictionary to store the benchmark results and define a helper function to get result for each approach:</p> <pre><code>results = {}\ndef get_result(approach, x_test, y_test):\ny_pred = approach.predict(x_test, verbose=0)\nfpr, tpr, _ = roc_curve(y_test, y_pred[:, 1])\nresult = {\napproach.name: {\n\"acc\": ops.convert_to_numpy(\nAccuracy()(y_test, y_pred.argmax(axis=1))\n).item(),\n\"auc\": ops.convert_to_numpy(AUC()(y_test, y_pred[:, 1])).item(),\n\"sig\": ops.convert_to_numpy(MaxSignificance()(y_test, y_pred)).item(),\n\"r50\": ops.convert_to_numpy(\nRejectionAtEfficiency(0.5)(y_test, y_pred)\n).item(),\n\"r99\": ops.convert_to_numpy(\nRejectionAtEfficiency(0.99)(y_test, y_pred)\n).item(),\n\"fpr\": fpr,\n\"tpr\": tpr,\n}\n}\nreturn result\n</code></pre>"},{"location":"guides/03_apply_approaches/#cut-and-count","title":"Cut and count","text":"<p><code>CutAndCount</code> approach is a simple cut-based analysis. It uses a set of cuts on observables to separate signal and background. It has two topologies to apply cuts: <code>parallel</code> and <code>sequential</code>. The <code>parallel</code> topology applies all cuts simultaneously, while the <code>sequential</code> topology applies cuts one by one.</p> <pre><code># Dataset\nds = load_dataset(\"./data/wjj_vs_qcd_set.ds\")\nx_train, y_train = ds.train.samples, ds.train.targets\nx_test, y_test = ds.test.samples, ds.test.targets\n</code></pre> <pre><code># Training\ncnc1 = CNC(\nn_observables=3,\ntopology=\"parallel\",\nname=\"cnc_parallel\",\n)\ncnc1.compile(\noptimizer=\"adam\",\nloss=\"crossentropy\",\nmetrics=[\"accuracy\"],\nrun_eagerly=True,\n)\ncnc1.fit(x_train, y_train, batch_size=len(x_train))\n</code></pre> <pre><code>1/1 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7s 7s/step - accuracy: 0.7631 - loss: 3.8179\n</code></pre> <pre><code># Training\ncnc2 = CNC(\nn_observables=3,\ntopology=\"sequential\",\nname=\"cnc_sequential\",\n)\ncnc2.compile(\noptimizer=\"adam\",\nloss=\"crossentropy\",\nmetrics=[\"accuracy\"],\nrun_eagerly=True,\n)\ncnc2.fit(x_train, y_train, batch_size=len(x_train))\n</code></pre> <pre><code>1/1 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 5s 5s/step - accuracy: 0.7968 - loss: 3.2749\n</code></pre> <p>We could see that the <code>sequential</code> topology has a better performance than the <code>parallel</code> topology. It's reasonable because the <code>sequential</code> topology applies cuts one by one, which determines the best cut according to the current distribution not the original one.</p> <p>Now add the results to the dictionary:</p> <pre><code>results.update(get_result(cnc1, x_test, y_test))\nresults.update(get_result(cnc2, x_test, y_test))\n</code></pre>"},{"location":"guides/03_apply_approaches/#gradient-boosted-decision-tree","title":"Gradient boosted decision tree","text":"<p>We adapt <code>GradientBoostingClassifier</code> from <code>sklearn</code> to work as a <code>Keras</code> model:</p> <pre><code># Dataset\nds = load_dataset(\"./data/wjj_vs_qcd_set.ds\")\nx_train, y_train = ds.train.samples, ds.train.targets\nx_test, y_test = ds.test.samples, ds.test.targets\n</code></pre> <pre><code># Training\nbdt = BDT(name=\"bdt\")\nbdt.compile(metrics=[\"accuracy\"])\nbdt.fit(x_train, y_train)\n</code></pre> <pre><code>100/100 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 19ms/step - loss: 0.2807 - accuracy: 0.9005\n</code></pre> <ul> <li>The <code>optimizer</code> and <code>loss</code> have any effect in <code>compile</code> because <code>sklearn</code> will handle them internally.</li> <li><code>batch_size</code> and <code>epochs</code> are irrelevant for a tree.</li> <li>The progress bar displays the number of estimators rather than training steps.</li> </ul> <p>Add the results to the dictionary:</p> <pre><code>results.update(get_result(bdt, x_test, y_test))\n</code></pre>"},{"location":"guides/03_apply_approaches/#simple-multi-layer-perceptron","title":"Simple multi-layer perceptron","text":"<p>Currently, HML provides a toy multi-layer perceptron to perform simple analysis:</p> <pre><code># Dataset\nds = load_dataset(\"./data/wjj_vs_qcd_set.ds\")\nx_train, y_train = ds.train.samples, ds.train.targets\nx_test, y_test = ds.test.samples, ds.test.targets\nscaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\n</code></pre> <pre><code>mlp = MLP(name=\"mlp\", input_shape=x_train.shape[1:])\nmlp.summary()\n</code></pre> <pre><code>Model: \"mlp\"\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 dense_4 (Dense)                 \u2502 (None, 32)             \u2502           128 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_5 (Dense)                 \u2502 (None, 64)             \u2502         2,112 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_6 (Dense)                 \u2502 (None, 32)             \u2502         2,080 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_7 (Dense)                 \u2502 (None, 2)              \u2502            66 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nTotal params: 4,386 (17.13 KB)\nTrainable params: 4,386 (17.13 KB)\nNon-trainable params: 0 (0.00 B)\n</code></pre> <pre><code># Training\nmlp.compile(loss=\"crossentropy\", metrics=[\"accuracy\"])\nmlp.fit(x_train, y_train, batch_size=128, epochs=100)\nresults.update(get_result(mlp, x_test, y_test))\n</code></pre> <pre><code>Epoch 1/100\n99/99 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2s 7ms/step - accuracy: 0.7073 - loss: 0.5788\nEpoch 2/100\n99/99 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 3ms/step - accuracy: 0.8625 - loss: 0.3370\n...\nEpoch 99/100\n99/99 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 3ms/step - accuracy: 0.8954 - loss: 0.2585\nEpoch 100/100\n99/99 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 3ms/step - accuracy: 0.9016 - loss: 0.2526\n</code></pre>"},{"location":"guides/03_apply_approaches/#simple-convolutional-neural-network","title":"Simple convolutional neural network","text":"<p>We also provide a toy CNN to perform simple analysis. There're two ways to normalize the images: using the maximum value of each image or applying <code>log</code> to each pixel.</p> <pre><code># Dataset\nds = load_dataset(\"./data/wjj_vs_qcd_image.ds\")\nx_train, y_train = ds.train.samples, ds.train.targets\nx_test, y_test = ds.test.samples, ds.test.targets\nnon_zero_train = x_train.reshape(x_train.shape[0], -1).sum(1) != 0\nnon_zero_test = x_test.reshape(x_test.shape[0], -1).sum(1) != 0\nx_train, y_train = x_train[non_zero_train], y_train[non_zero_train]\nx_test, y_test = x_test[non_zero_test], y_test[non_zero_test]\nx_train = (\nx_train.reshape(len(x_train), -1)\n/ x_train.reshape(len(x_train), -1).max(1, keepdims=True)\n).reshape(x_train.shape)\nx_test = (\nx_test.reshape(len(x_test), -1)\n/ x_test.reshape(len(x_test), -1).max(1, keepdims=True)\n).reshape(x_test.shape)\nx_train = x_train[..., None]\nx_test = x_test[..., None]\n</code></pre> <pre><code>cnn1 = CNN(name=\"cnn_max\", input_shape=x_train.shape[1:])\ncnn1.summary()\n</code></pre> <pre><code>Model: \"cnn_max\"\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 conv2d_3 (Conv2D)               \u2502 (None, 33, 33, 8)      \u2502            80 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv2d_4 (Conv2D)               \u2502 (None, 16, 16, 16)     \u2502         1,168 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 conv2d_5 (Conv2D)               \u2502 (None, 8, 8, 32)       \u2502         4,640 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 max_pooling2d_1 (MaxPooling2D)  \u2502 (None, 4, 4, 32)       \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 global_average_pooling2d_1      \u2502 (None, 32)             \u2502             0 \u2502\n\u2502 (GlobalAveragePooling2D)        \u2502                        \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dropout_1 (Dropout)             \u2502 ?                      \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_10 (Dense)                \u2502 (None, 2)              \u2502            66 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_11 (Dense)                \u2502 (None, 2)              \u2502             6 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nTotal params: 5,960 (23.28 KB)\nTrainable params: 5,960 (23.28 KB)\nNon-trainable params: 0 (0.00 B)\n</code></pre> <pre><code># Training\ncnn1.compile(\noptimizer=\"adam\",\nloss=\"crossentropy\",\nmetrics=[\"accuracy\"],\n)\ncnn1.fit(\nx_train,\ny_train,\nepochs=100,\nbatch_size=128,\n)\nresults.update(get_result(cnn1, x_test, y_test))\n</code></pre> <pre><code>Epoch 1/100\n98/98 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 4s 18ms/step - accuracy: 0.5386 - loss: 0.6891\nEpoch 2/100\n98/98 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 4ms/step - accuracy: 0.5982 - loss: 0.6491\n...\nEpoch 99/100\n98/98 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 4ms/step - accuracy: 0.8107 - loss: 0.4378\nEpoch 100/100\n98/98 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 4ms/step - accuracy: 0.8104 - loss: 0.4392\n</code></pre> <pre><code># Dataset\nds = load_dataset(\"./data/wjj_vs_qcd_image.ds\")\nx_train, y_train = ds.train.samples, ds.train.targets\nx_test, y_test = ds.test.samples, ds.test.targets\nnon_zero_train = x_train.reshape(x_train.shape[0], -1).sum(1) != 0\nnon_zero_test = x_test.reshape(x_test.shape[0], -1).sum(1) != 0\nx_train, y_train = x_train[non_zero_train], y_train[non_zero_train]\nx_test, y_test = x_test[non_zero_test], y_test[non_zero_test]\nx_train = np.log(x_train + 1)\nx_test = np.log(x_test + 1)\nx_train = x_train[..., None]\nx_test = x_test[..., None]\n</code></pre> <pre><code># Training\ncnn2 = CNN(name=\"cnn_log\", input_shape=x_train.shape[1:])\ncnn2.compile(\noptimizer=\"adam\",\nloss=\"crossentropy\",\nmetrics=[\"accuracy\"],\n)\ncnn2.fit(\nx_train,\ny_train,\nepochs=100,\nbatch_size=128,\n)\nresults.update(get_result(cnn2, x_test, y_test))\n</code></pre> <pre><code>Epoch 1/100\n98/98 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3s 13ms/step - accuracy: 0.5350 - loss: 0.6880\nEpoch 2/100\n98/98 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 4ms/step - accuracy: 0.6368 - loss: 0.6431\n...\nEpoch 99/100\n98/98 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 4ms/step - accuracy: 0.8183 - loss: 0.4266\nEpoch 100/100\n98/98 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 4ms/step - accuracy: 0.8174 - loss: 0.4242\n</code></pre>"},{"location":"guides/03_apply_approaches/#evaluation","title":"Evaluation","text":"<pre><code>table = Table(\n\"Name\",\n\"ACC\",\n\"AUC\",\n\"Significance\",\n\"R50\",\n\"R99\",\ntitle=\"Approach Comparison\",\n)\nfor name, metrics in results.items():\ntable.add_row(\nname,\nf\"{metrics['acc']:.6f}\",\nf\"{metrics['auc']:.6f}\",\nf\"{metrics['sig']:.6f}\",\nf\"{metrics['r50']:.6f}\",\nf\"{metrics['r99']:.6f}\",\n)\ntable\n</code></pre> <pre>\n                             Approach Comparison                              \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Name           \u2503 ACC      \u2503 AUC      \u2503 Significance \u2503 R50       \u2503 R99      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 cnc_parallel   \u2502 0.765086 \u2502 0.743599 \u2502 34.742661    \u2502 4.256874  \u2502 1.000000 \u2502\n\u2502 cnc_sequential \u2502 0.805868 \u2502 0.788848 \u2502 37.796890    \u2502 5.151141  \u2502 1.000000 \u2502\n\u2502 bdt            \u2502 0.899797 \u2502 0.952525 \u2502 44.131214    \u2502 86.015831 \u2502 1.997420 \u2502\n\u2502 mlp            \u2502 0.897583 \u2502 0.952662 \u2502 44.056389    \u2502 96.767815 \u2502 1.953497 \u2502\n\u2502 cnn_max        \u2502 0.806482 \u2502 0.868102 \u2502 38.510403    \u2502 16.526314 \u2502 1.191518 \u2502\n\u2502 cnn_log        \u2502 0.808917 \u2502 0.873000 \u2502 38.833694    \u2502 17.852850 \u2502 1.232795 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre><code>for name, metrics in results.items():\nfpr = metrics[\"fpr\"]\ntpr = metrics[\"tpr\"]\nplt.plot(fpr, tpr, label=f\"{name}\")\nplt.title(\"ROC Curves\")\nplt.xlabel(\"Efficiency\")\nplt.ylabel(\"Mistag Rate\")\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"guides/03_apply_approaches/#plot-the-cuts-on-distributions","title":"Plot the cuts on distributions","text":"<pre><code>ds = load_dataset(\"./data/wjj_vs_qcd_set.ds\")\nx_train, y_train = ds.train.samples, ds.train.targets\nx_test, y_test = ds.test.samples, ds.test.targets\n</code></pre> <pre><code>fig, axs = plt.subplots(1, 3, figsize=(15, 5))\nfor i in range(x_train.shape[1]):\nlayer = cnc1.cut_layers[i]\nobservable = ds.feature_names[i]\nbin_edges = np.linspace(\nx_train[:, i].min(), x_train[:, i].max(), cnc1.n_bins + 1\n)\naxs[i].hist(x_test[:, i][y_test == 0], bins=bin_edges, alpha=0.5, label=\"0\")\naxs[i].hist(x_test[:, i][y_test == 1], bins=bin_edges, alpha=0.5, label=\"1\")\ny_min, y_max = axs[i].get_ylim()\naxs[i].vlines(bin_edges, y_min, y_max, color=\"k\", ls=\"dashed\", lw=0.5)\nif layer.case == 0:\naxs[i].vlines(layer.cut_left, y_min, y_max, color=\"r\", label=layer.cut)\nelif layer.case == 1:\naxs[i].vlines(layer.cut_right, y_min, y_max, color=\"r\", label=layer.cut)\nelif layer.case == 2:\naxs[i].vlines(layer.cut_left, y_min, y_max, color=\"r\", label=layer.cut)\naxs[i].vlines(layer.cut_right, y_min, y_max, color=\"r\")\nelse:\naxs[i].vlines(layer.cut_left, y_min, y_max, color=\"r\", label=layer.cut)\naxs[i].vlines(layer.cut_right, y_min, y_max, color=\"r\")\naxs[i].set_title(f\"{observable}\")\naxs[i].legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code>fig, axs = plt.subplots(1, 3, figsize=(15, 5))\nfor i in range(x_train.shape[1]):\nlayer = cnc2.cut_layers[i]\nobservable = ds.feature_names[i]\nbin_edges = np.linspace(\nx_train[:, i].min(), x_train[:, i].max(), cnc2.n_bins + 1\n)\naxs[i].hist(x_test[:, i][y_test == 0], bins=bin_edges, alpha=0.5, label=\"0\")\naxs[i].hist(x_test[:, i][y_test == 1], bins=bin_edges, alpha=0.5, label=\"1\")\ny_min, y_max = axs[i].get_ylim()\naxs[i].vlines(bin_edges, y_min, y_max, color=\"k\", ls=\"dashed\", lw=0.5)\nif layer.case == 0:\naxs[i].vlines(layer.cut_left, y_min, y_max, color=\"r\", label=layer.cut)\nelif layer.case == 1:\naxs[i].vlines(layer.cut_right, y_min, y_max, color=\"r\", label=layer.cut)\nelif layer.case == 2:\naxs[i].vlines(layer.cut_left, y_min, y_max, color=\"r\", label=layer.cut)\naxs[i].vlines(layer.cut_right, y_min, y_max, color=\"r\")\nelse:\naxs[i].vlines(layer.cut_left, y_min, y_max, color=\"r\", label=layer.cut)\naxs[i].vlines(layer.cut_right, y_min, y_max, color=\"r\")\naxs[i].set_title(f\"{observable}\")\naxs[i].legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code>cut_layers = cnc2.cut_layers\nmask_train = ops.squeeze(ops.where(ops.ones(x_train.shape[0]) == 1))\nmask_test = ops.squeeze(ops.where(ops.ones(x_test.shape[0]) == 1))\nplt.figure(figsize=(15, 5))\nfor i in range(x_train.shape[1]):\nplt.subplot(1, 3, i + 1)\nlayer = cut_layers[i]\nmasked_x_train = ops.convert_to_numpy(ops.take(x_train[:, i], mask_train))\nmasked_y_train = ops.convert_to_numpy(ops.take(y_train, mask_train))\nbin_edges = np.linspace(masked_x_train.min(), masked_x_train.max(), 50 + 1)\nmask_train = ops.squeeze(ops.where(cut_layers[i].apply_cut(x_train) == 1))\nmasked_x_test = ops.convert_to_numpy(ops.take(x_test[:, i], mask_test))\nmasked_y_test = ops.convert_to_numpy(ops.take(y_test, mask_test))\nmask_test = ops.squeeze(ops.where(cut_layers[i].apply_cut(x_test) == 1))\nplt.hist(masked_x_test[masked_y_test == 0], bins=bin_edges, alpha=0.5, label=\"0\")\nplt.hist(masked_x_test[masked_y_test == 1], bins=bin_edges, alpha=0.5, label=\"1\")\ny_min, y_max = plt.gca().get_ylim()\nplt.vlines(bin_edges, y_min, y_max, color=\"k\", ls=\"dashed\", lw=0.5)\nif layer.case == 0:\nplt.vlines(layer.cut_left, y_min, y_max, color=\"r\", label=layer.cut)\nelif layer.case == 1:\nplt.vlines(layer.cut_left, y_min, y_max, color=\"r\", label=layer.cut)\nelif layer.case == 2:\nplt.vlines(layer.cut_left, y_min, y_max, color=\"r\", label=layer.cut)\nplt.vlines(layer.cut_right, y_min, y_max, color=\"r\")\nelse:\nplt.vlines(layer.cut_left, y_min, y_max, color=\"r\", label=layer.cut)\nplt.vlines(layer.cut_right, y_min, y_max, color=\"r\")\nplt.title(ds.feature_names[i])\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"guides/03_apply_approaches/#save-and-load-approaches","title":"Save and load approaches","text":"<p>After <code>fit</code> each approach, use <code>save</code> to save it to a file. To make folder structure clean, let\u2019s create a folder named \u201ccheckpoints\u201d first:</p> <pre><code>mkdir checkpoints\n</code></pre> <p>Then, in your codes or the notebook:</p> <pre><code>cnc1.save(\"./checkpoints/cnc_parallel.keras\")\ncnc2.save(\"./checkpoints/cnc_sequential.keras\")\nbdt.save(\"./checkpoints/bdt.pickle\")\nmlp.save(\"./checkpoints/mlp.keras\")\ncnn1.save(\"./checkpoints/cnn1.keras\")\ncnn2.save(\"./checkpoints/cnn2.keras\")\n</code></pre> <p>Once again, we use <code>load_approach</code> to let HML decide which class it actually is, just like <code>parse_observable</code>, <code>load_dataset</code>:</p> <pre><code>loaded_cnc1 = load_approach(\"./checkpoints/cnc_parallel.keras\")\nloaded_cnc2 = load_approach(\"./checkpoints/cnc_sequential.keras\")\nloaded_bdt = load_approach(\"./checkpoints/bdt.pickle\")\nloaded_mlp = load_approach(\"./checkpoints/mlp.keras\")\nloaded_cnn1 = load_approach(\"./checkpoints/cnn1.keras\")\nloaded_cnn2 = load_approach(\"./checkpoints/cnn2.keras\")\n</code></pre> <p>Check the doc to learn more about cuts, trees, and networks.</p>"},{"location":"install/docker/","title":"Use hep-ml-lab in Docker","text":""},{"location":"install/docker/#hml-env-image","title":"hml-env image","text":"<p><code>hml-env</code> is a comprehensive programming environment designed to facilitate research and development at the intersection of high-energy physics and machine learning. </p> <p>This image is based on <code>nvidia/cuda:11.8.0-cudnn8-devel-ubuntu20.04</code>. Below is a pre-installed software list:</p> Type Version General shell: zsh (oh-my-zsh) Python: 3.11.5 (Miniconda) High energy physics ROOT: 6.26.14 LHAPDF: 6.5.3 MadGraph5_aMC@NLO: 3.5.3 (with Pythia8 and Delphes installed) <p>You can use <code>hep-ml-lab</code> in a Docker container. The Docker image (<code>hml-env</code>) is available on Docker Hub. This way, you can avoid the hassle of installing the NVIDIA\u00ae softwares.</p>"},{"location":"install/docker/#prerequisites","title":"Prerequisites","text":"<p>However, you still need to install the NVIDIA\u00ae drivers on your host machine. The <code>hml-env</code> image is built on top of the <code>nvidia/cuda</code> image, which requires the NVIDIA\u00ae drivers to be installed on the host machine. Check the official page for more details of prerequisites.</p>"},{"location":"install/docker/#start-a-container","title":"Start a container","text":"<p>Once you have installed the NVIDIA\u00ae drivers, you can pull the <code>hml-env</code> image with the following command:</p> <pre><code>docker pull star9daisy/hml-env\n</code></pre> <p>Then start a container with the following command:</p> <pre><code>docker run -it --gpus all star9daisy/hml-env\n</code></pre>"},{"location":"install/docker/#use-pip-to-continue-installation-of-hep-ml-lab","title":"Use <code>pip</code> to continue installation of <code>hep-ml-lab</code>","text":"<p>Check this part in the pip installation guide for more details.</p>"},{"location":"install/pip/","title":"Install hep-ml-lab with pip","text":""},{"location":"install/pip/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python &gt;= 3.9</li> <li>ROOT v6.26/14 (other versions should be OK. Required by Delphes)</li> <li>Madgraph5 v3.5.3 (other versions should be OK)<ul> <li>pythia8 v8.306 (installed by Madgraph5)</li> <li>Delphes v3.5.0 (installed by Madgraph5)</li> </ul> </li> </ul> <p>The <code>keras</code> 3.0 requires the <code>tensorflow</code> 2.16 or higher, which is also the latest version. Before installing <code>tensorflow</code>, you need to install the following NVIDIA\u00ae softwares:</p> <ul> <li>NVIDIA\u00ae GPU drivers version 450.80.02 or higher.</li> <li>CUDA\u00ae Toolkit 11.8.</li> <li>cuDNN SDK 8.6.0.</li> </ul> <p>Check the offical page of tensorflow for more details.</p>"},{"location":"install/pip/#installation","title":"Installation","text":"<pre><code>pip install hep-ml-lab\n</code></pre> <p>This will install the latest version of <code>keras</code> without any backends such as <code>tensorflow</code>, <code>pytorch</code> or <code>jax</code>. Since we have only tested <code>hep-ml-lab</code> on <code>tensorflow</code>, here we show how to install <code>tensorflow</code> as a backend. Then you can install <code>tensorflow</code> with the following command</p> <pre><code>pip install tensorflow[and-cuda]\n</code></pre>"},{"location":"install/pip/#fix-the-issue-with-tensorflow-216","title":"Fix the issue with tensorflow 2.16","text":"<p>There's an known issue with <code>tensorflow</code> 2.16: it couldn't recognize GPUs smoothly like before. So we have to link the related libraries manually. Use the following script to do so:</p> <pre><code># set_nvidia.sh\n# Attempt to locate the NVIDIA cudnn library file using Python.\nNVIDIA_DIR=$(python -c \"import nvidia.cudnn; print(nvidia.cudnn.__file__)\" 2&gt;/dev/null)\n# Check if the NVIDIA directory variable is set (i.e., cudnn was found).\nif [ ! -z \"$NVIDIA_DIR\" ]; then\n# Get the parent directory of the directory containing the __file__\nNVIDIA_DIR=$(dirname $(dirname $NVIDIA_DIR))\n# Iterate over all directories in the NVIDIA package directory.\nfor dir in $NVIDIA_DIR/*; do\n# Check if the directory has a 'lib' subdirectory.\nif [ -d \"$dir/lib\" ]; then\n# Prepend the library path to LD_LIBRARY_PATH.\nexport LD_LIBRARY_PATH=\"$dir/lib:$LD_LIBRARY_PATH\"\nfi\ndone\nfi\n</code></pre> <p>Run it in the environment where you installed <code>tensorflow</code>:</p> <pre><code>source set_nvidia.sh\n</code></pre> <p>Now you can test if <code>tensorflow</code> recognizes your GPUs:</p> <pre><code>python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n</code></pre> <p>If it is set up successfully, you will see the following output: <pre><code>[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n</code></pre></p> <p>If you are in a conda environment and want to source it automatically, you can follow the steps below:</p> <pre><code># Step1: Check the path of the conda environment\nconda env list\n\n# the path should look like\n# /root/miniconda3/envs/py39\ncd &lt;path_to_the_environment&gt;\n\n# Step2: Create the folder if it doesn't exist\nmkdir -p etc/conda/activate.d\n\n# Step3: Copy the script to the folder\ncp set_nvidia.sh etc/conda/activate.d/set_nvidia.sh\n\n# Step4: Reopen the conda environment\nconda activate &lt;env_name&gt;\n</code></pre>"}]}